{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "PROJECT_ID = \"<YOUR_PROJECT_ID>\"  \n",
    "REGION = \"<YOUR_REGION>\"\n",
    "CREDS_PATH = \"<PROJECT_API_KEY_PATH>\"  \n",
    "\n",
    "try:\n",
    "    credentials = service_account.Credentials.from_service_account_file(\n",
    "        CREDS_PATH, scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    "    )\n",
    "except:\n",
    "    print(\"Error while getting service account credentials!\")\n",
    "\n",
    "\n",
    "vertexai.init(credentials=credentials, project=PROJECT_ID, location=REGION)\n",
    "print(\"Vertex AI initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain_community.vectorstores.chroma import Chroma\n",
    "from langchain_google_vertexai import VertexAIEmbeddings, ChatVertexAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_experimental.text_splitter import  SemanticChunker\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain import hub\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "import wikipediaapi\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_wiki = wikipediaapi.Wikipedia(user_agent='sample-rag/1.0 (vancence.ho@ollion.com)', language='en')\n",
    "\n",
    "def fetch_wiki_page(title):\n",
    "    page = wiki_wiki.page(title)\n",
    "    if page.exists():\n",
    "        return page.text\n",
    "    else:\n",
    "        return None \n",
    "    \n",
    "print(\"Wikipedia API initialized as: wiki_wiki!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = [\"Python (programming language)\", \"Artificial Intelligence\", \"Machine Learning\", \"Natural Language Processing\", \"Retrieval Augmented Generation\", \"OpenAI\", \"Deep Learning\"]\n",
    "\n",
    "documents = []\n",
    "\n",
    "for title in article_titles:\n",
    "    content = fetch_wiki_page(title)\n",
    "    if content:\n",
    "        documents.append(Document(page_content=content, metadata={\"title\": title, \"source\": \"Wikipedia\"}))\n",
    "\n",
    "print(f\"Number of documents fetched: {len(documents)}\")\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = VertexAIEmbeddings(model_name=\"text-embedding-004\", credentials=credentials, project=PROJECT_ID, region=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=50, add_start_index=True)\n",
    "splits = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_store = Chroma.from_documents(documents=splits, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = chroma_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3}) # Retrieve top 3 similar documents as context for the llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatVertexAI(\n",
    "    \n",
    "    model=\"gemini-1.5-flash-001\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    max_retries=3,\n",
    "    stop=None,\n",
    "    credentials=credentials, \n",
    "    project=PROJECT_ID, \n",
    "    location=REGION\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "print(f\"LLM initialized with model: {llm.model_name}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful chatbot that can provide information about various topics. \"\n",
    "            \"You can answer questions, provide explanations, and give examples. \"\n",
    "            \"You can also ask questions to clarify the user's intent. \"\n",
    "            \"You can also provide links to relevant resources. \"\n",
    "            \"Use the following pieces of retrieved context to answer the user's question. \"\n",
    "            \"If you don't know the answer, say that you don't know. \"\n",
    "            \"Use three sentences maximum and keep the answer simple and concise. \"\n",
    "            \"\\n\\n\"\n",
    "            \"Context: {context}\" \n",
    "            \n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"{input}\"\n",
    "            \n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilising built-in chains\n",
    "\n",
    "- `create_stuff_documents_chain`\n",
    "- `create_retrieval_chain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt_template)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain.invoke({\"input\": \"When is Python 2.0 released?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilising normal chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain2 = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"input\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt_template\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain2.invoke(\"when is python 2.0 released?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_store.delete_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "prompt_template.format(adjective=\"funny\", content=\"chickens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "output = chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"Korean\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
